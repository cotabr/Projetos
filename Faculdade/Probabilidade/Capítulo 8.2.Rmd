---
title: "Cap√≠tulo 8.2 - Esperan√ßa"
author: 
- Denilson Silva (Discente)
- Dr. Rafael Suzuki Bayma (Docente)
date: "`r format(Sys.time(), '%d/%m/%y')`"
output: 
  rmdformats::readthedown
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(reticulate)
```

<p ALIGN=justify>Ao explorarmos a fun√ß√£o de distribui√ß√£o de probabilidade, frequentemente nos deparamos com detalhes excessivos que podem obscurecer a compreens√£o da vari√°vel aleat√≥ria em quest√£o. Em alguns casos, a utiliza√ß√£o de medidas estat√≠sticas mais simples, como a m√©dia e a vari√¢ncia, pode oferecer uma descri√ß√£o mais concisa e compreens√≠vel da vari√°vel aleat√≥ria.</p>

<p ALIGN=justify>Na estat√≠stica, a esperan√ßa, simbolizada pelo operador $E[x^{n}]$ ou o momento de ordem $n$ de uma vari√°vel, desempenha um papel crucial na s√≠ntese de informa√ß√µes sobre a distribui√ß√£o. O operador $E$ representa o valor esperado ou a esperan√ßa, e sua aplica√ß√£o permite resumir caracter√≠sticas importantes da vari√°vel aleat√≥ria.</p>

<p ALIGN=justify>A esperan√ßa √©, essencialmente, o valor m√©dio esperado de uma vari√°vel. Considerando uma vari√°vel aleat√≥ria cont√≠nua $X$ com fun√ß√£o densidade $f$, a esperan√ßa matem√°tica ou m√©dia de $X$, denotada por $E(X)$, √© definida como:</p>

$$
E(X) = \int_{-\infty}^{\infty} x \cdot f(x) \,dx \tag{8.33}
$$

<p ALIGN=justify>Esta express√£o representa a integral do produto do valor da vari√°vel $x$ e sua fun√ß√£o densidade $f(x)$ em rela√ß√£o a todos os poss√≠veis valores de $x$. Em outras palavras, a esperan√ßa √© uma medida que resume a tend√™ncia central da distribui√ß√£o de probabilidade de $X$.</p>

<p ALIGN=justify>Assim, ao empregar o conceito de esperan√ßa, podemos simplificar a descri√ß√£o de vari√°veis aleat√≥rias e concentrar-nos em aspectos essenciais de sua distribui√ß√£o, proporcionando uma compreens√£o mais clara e eficaz em contextos estat√≠sticos e probabil√≠sticos.</p>

# M√©dia

<p ALIGN=justify>Como a m√©dia √© uma medida sens√≠vel aos valores da amostra, √© mais adequada para situa√ß√µes em que os dados s√£o distribu√≠dos mais ou menos de forma uniforme, ou seja, valores sem grandes discrep√¢ncias. Para uma vari√°vel aleat√≥ria discreta X, a m√©dia, $\mu_x$, √© a soma ponderada de todas as poss√≠veis sa√≠das. Sendo assim temos que:</p>

\begin{align*}
\mu_X &= E[x]
\mu_X &= \sum_x xP[X=x]  \tag{8.32}
\end{align*}

<p ALIGN=justify>na qual o somat√≥rio ocorre para todas as poss√≠veis sa√≠das da vari√°vel aleat√≥ria X. Para uma vari√°vel aleat√≥ria cont√≠nua com fun√ß√£o de densidade fX(x), a defini√ß√£o an√°loga de valor esperado √© </p>

$$
E[X]=\int_{-\infty}^{+\infty} xf(x) \, dx \tag{8.33}
$$


<p ALIGN=justify>Geralmente o valor m√©dio de uma vari√°vel aleat√≥ria √© estimado de $N$ observa√ß√µes da vari√°vel aleat√≥ria $\{x_1, x_2, .., x_N\}$, usando o estimador.</p>

$$\hat{\mu}_X =\frac{1}{N}\sum_{(n=1)}^{N}x_n \tag{8.34}$$

<p ALIGN=justify>Ou seja, estimamos a m√©dia da distribui√ß√£o calculando o valor m√©dio em um determinado n√∫mero de observa√ß√µes da vari√°vel aleat√≥ria. Este estimador √© baseado na defini√ß√£o de freq√º√™ncia relativa de probabilidade. Por exemplo, se as poss√≠veis sa√≠das da vari√°vel aleat√≥ria Z s√£o 1, 2, 3, ..., M, ent√£o o estimador se torna,</p>

$$\hat{\mu} = \frac{ 1 \cdot n_1 + 2 \cdot n_2 + \cdot \cdot \cdot+ M \cdot n_m}{N}$$

<p ALIGN=justify>no qual $ni$ √© o n√∫mero de vezes que a observa√ß√£o $Z = i$ ocorre. Podemos reescrever esta equa√ß√£o como:</p>

$$\hat{\mu} = \sum_{i=1}^{M}i\frac{n_i}{N}$$  
$$\approx \sum_{i=1}^{M}iP[Z=i]$$

<p ALIGN=justify>Ou seja, esperamos que as sa√≠das mais prov√°veis ocorram mais frequentemente quando um n√∫mero de observa√ß√µes √© feito.cRetornando ao caso geral, se consideramos X como vari√°vel aleat√≥ria representando as observa√ß√µes da tens√£o de um sinal aleat√≥rio, ent√£o o valor m√©dio de X representa a tens√£o m√©dia ou n√≠vel CC do sinal.</p>

<p ALIGN=justify>Exemplo 1: podemos observar na Figura 1 os valores de vendas de carros em uma consecionaria de carros no decorrer do ano. A m√©dia anual de vendas de carros pode-ser obtida facilmente a partir da Equa√ß√£o 8.34.</p>

```{python, fig.align='center', fig.width=6, fig.height=5}
import matplotlib.pyplot as plt
import numpy as np
def plot_vendas_carros(ano, vendas_por_mes):
    meses = list(range(1, 13))  # Lista de meses de janeiro a dezembro
    plt.plot(meses, vendas_por_mes, marker='o', linestyle='-', color='b')
    plt.xlabel('M√™s')
    plt.ylabel('Vendas de Carros')
    plt.title(f'Figura 1:Vendas de Carros na Concession√°ria - {ano}')
    plt.xticks(meses, ['Jan', 'Fev', 'Mar', 'Abr', 'Mai', 'Jun', 'Jul', 'Ago', 'Set', 'Out', 'Nov', 'Dez'])
    plt.grid(True)
    plt.show()

# Exemplo de uso da fun√ß√£o
ano = 2023
vendas_por_mes = [50, 60, 45, 70, 55, 70, 75, 65, 72, 70, 75, 80]
plot_vendas_carros(ano, vendas_por_mes)

```

<p ALIGN=justify>A m√©dia pode ser calculada de inumeras formas no python, as maneiras mais convencionais s√£o atrav√©s da propria defini√ß√£o da mepdia, que √© definida pelo somat√≥rio dos termos divididos pela quantidade de elementos.</p>

```{python}
import numpy as np
media_aritimetica = round(sum(vendas_por_mes)/len(vendas_por_mes),3)
media_numpy = round(np.mean(vendas_por_mes),3)

print("Vendas por m√™s:", vendas_por_mes)
print("M√©dia das vendas anuais:", media_aritimetica)
print("M√©dia das vendas anuais:", media_numpy)
```

<p ALIGN=justify>Um problema bastante encontrando nessa m√©trica √© quando no conjunto de daods existem valores com valores discrepantes com rela√ß√£o aos demais valores.</p>

```{python, fig.align='center', fig.width=6, fig.height=5}
import matplotlib.pyplot as plt

def plot_indice_precipitacao_3_anos(indice_precipitacao):
    anos = list(range(1, 4))  # Lista de anos de 1 a 3
    meses = list(range(1, 13))  # Lista de meses de janeiro a dezembro

    plt.figure(figsize=(10, 6))
    for ano, indice_anual in zip(anos, indice_precipitacao):
        plt.plot(meses, indice_anual, marker='o', linestyle='-', label=f'Ano {ano}')

    plt.xlabel('M√™s')
    plt.ylabel('√çndice de Precipita√ß√£o')
    plt.title('√çndices de Precipita√ß√£o de Chuvas ao Longo de 3 Anos')
    plt.xticks(meses, ['Jan', 'Fev', 'Mar', 'Abr', 'Mai', 'Jun', 'Jul', 'Ago', 'Set', 'Out', 'Nov', 'Dez'])
    plt.grid(True)
    plt.legend()
    plt.show()

# Exemplo de uso da fun√ß√£o
# Os dados s√£o fict√≠cios apenas para fins ilustrativos
indice_precipitacao_3_anos = [
    [100, 80, 125, 90, 88, 70, 50, 60, 95, 120, 130, 110],  # Ano 1
    [90, 85, 130, 88, 90, 90, 55, 75, 100, 115, 120, 100],  # Ano 2
    [110, 100, 140, 90, 95, 80, 60, 65, 105, 125, 135, 105],  # Ano 3
    # Adicione os dados dos demais anos aqui...
]
ano1 =[100, 80, 125, 90, 88, 70, 50, 60, 95, 120, 130, 110],  # Ano 1
ano2 = [90, 85, 130, 88, 90, 90, 55, 75, 100, 115, 120, 100],  # Ano 2
ano3 =[110, 100, 140, 90, 95, 80, 60, 65, 105, 125, 135, 105],  # Ano 3
plot_indice_precipitacao_3_anos(indice_precipitacao_3_anos)
```

```{python}
print("Media de pricipita√ß√£o no ano 1:", round(np.mean(ano1),3))
print("Media de pricipita√ß√£o no ano 2:", round(np.mean(ano2),3))
print("Media de pricipita√ß√£o no ano 3:", round(np.mean(ano3),3))
# ao substituirmos no ano 1 o valor do m√™s de agosto, por valor elavado, ja teremos uma forte mudan√ßa no valor da m√©dia
```

# Vari√¢ncia

<p ALIGN=justify>A vari√¢ncia √© uma medida estat√≠stica e probabil√≠stica fundamental que desempenha um papel essencial na an√°lise de dados, fornecendo insights sobre a dispers√£o e a estabilidade das informa√ß√µes. Tanto na abordagem estat√≠stica quanto na probabil√≠stica, a vari√¢ncia desempenha fun√ß√µes distintas, mas interligadas.</p>

<p ALIGN=justify>Na estat√≠stica descritiva, a vari√¢ncia √© uma ferramenta valiosa para avaliar o qu√£o longe os valores de um conjunto est√£o da m√©dia. A vari√¢ncia $\sigma^2$ para a popula√ß√£o, $s^2$ para a amostra √© calculada como a m√©dia dos quadrados das diferen√ßas entre cada ponto de dados e a m√©dia do conjunto. Isso proporciona uma medida da dispers√£o dos dados em rela√ß√£o √† m√©dia.</p>

<p ALIGN=justify>A f√≥rmula para a vari√¢ncia populacional √©:</p>

$$\sigma^2 = \frac{1}{N} \sum_{i=1}^{N} (X_i - \mu)^2 $$

<p ALIGN=justify>Onde $N$ √© o tamanho da popula√ß√£o, $X_i$ √© cada valor individual, $\mu$ √© a m√©dia da popula√ß√£o.</p>

<p ALIGN=justify>Considere duas turmas de alunos com m√©dias id√™nticas, mas com vari√¢ncias diferentes. A Turma A tem uma vari√¢ncia de 10, indicando uma dispers√£o moderada, enquanto a Turma B tem uma vari√¢ncia de 30, indicando uma dispers√£o mais ampla. A vari√¢ncia oferece uma vis√£o mais detalhada da variabilidade nos resultados.</p>

<p ALIGN=justify>Na teoria das probabilidades, a vari√¢ncia √© fundamental ao avaliar a dispers√£o de uma distribui√ß√£o de probabilidade. Para uma vari√°vel aleat√≥ria discreta $X$, a vari√¢ncia $Var(X)$ √© definida como:</p>

$$Var(X) = E[(X - \mu)^2] $$

<p ALIGN=justify>Onde $E$ √© o operador de esperan√ßa e $\mu$ √© a m√©dia da distribui√ß√£o. A vari√¢ncia em termos probabil√≠sticos fornece informa√ß√µes sobre a dispers√£o dos resultados poss√≠veis em torno da m√©dia.</p>

<p ALIGN=justify>Considere uma distribui√ß√£o de probabilidade modelando o tempo de chegada de √¥nibus em uma parada. Uma vari√¢ncia baixa indicaria tempos consistentes, enquanto uma vari√¢ncia alta indicaria maior variabilidade nos tempos de chegada.</p>

<p ALIGN=justify>A vari√¢ncia √© uma medida vers√°til que desempenha um papel crucial em diversas disciplinas. Seja na estat√≠stica descritiva, fornecendo informa√ß√µes sobre a dispers√£o de dados, ou na teoria probabil√≠stica, auxiliando na compreens√£o da variabilidade em distribui√ß√µes de probabilidade, a vari√¢ncia √© uma ferramenta valiosa na an√°lise de dados e na modelagem de fen√¥menos diversos.</p>

<p ALIGN=justify>A vari√¢ncia de uma vari√°vel aleat√≥ria √© uma estimativa do espalhamento da distribui√ß√£o de probabilidade ao redor da m√©dia. Para vari√°veis aleat√≥rias, a vari√¢ncia $\sigma_{X}^{2}$ √© dada pela esperan√ßa da dist√¢ncia quadr√°tica de cada sa√≠da para o valor m√©dio da distribui√ß√£o.</p>

$$\sigma_{X}^{2} = Var(X) \\
  \sigma_{X}^{2}= E[(X-\mu_x)^2] \\
   \sigma_{X}^{2}  = \sum_x (x-\mu_x)^2 P[X=x]\tag{8.35}$$

<p ALIGN=justify>Para uma vari√°vel aleat√≥ria cont√≠nua com fun√ß√£o de densidade $f_{X}(x)$, a defini√ß√£o an√°loga de vari√¢ncia √© dada por:</p>

$$\sigma_{x}^{2} = \int_{-\infty}^{\infty} (x-\sigma_x)^2 \cdot f(X)x \,dx \tag{8.36}$$

<p ALIGN=justify>Uma equa√ß√£o simplificada pode ser mais usual na defini√ß√£o da vari√¢ncia, conforme mostrado na Equa√ß√£o 8.36.</p>

$$ 
\sigma^{2} = \frac{1}{N-1} \sum_{n=1}^{N} (x_n - \hat{\mu}_{x})^2 \tag{8.37}
$$

<p ALIGN=justify>O fator N/(N ‚Äì 1) que aparece no lado direito da Eq  √© devido √† considera√ß√£o de que as mesmas $N$ observa√ß√µes s√£o utilizadas para estimar o valor m√©dio . Com este fator, o valor esperado do lado direito √© $\sigma^{2}$ $Z$ e, conseq√ºentemente, a Equa√ß√£o 8.37 √© um estimador n√£o polarizado da vari√¢ncia. Dizemos que √© um estimador n√£o polarizado de $g$.</p>

<p ALIGN=justify>Se considerarmos $X$ como uma vari√°vel aleat√≥ria representando observa√ß√µes da tens√£o de um sinal aleat√≥rio, ent√£o a vari√¢ncia representa a pot√™ncia CA do sinal. O segundo momento de $X$, $E[X2]$, tamb√©m √© chamado valor m√©dio quadr√°tico do sinal aleat√≥rio e representa fisicamente a pot√™ncia total do sinal.</p>

```{python}
import random

# Defina o tamanho do conjunto de dados
tamanho_do_conjunto = 10

# Gere uma lista de n√∫meros aleat√≥rios
conjunto_de_dados = [random.uniform(0, 3) for _ in range(tamanho_do_conjunto)]

# Calcule a m√©dia dos n√∫meros no conjunto de dados
media = sum(conjunto_de_dados) / tamanho_do_conjunto

# Imprima o conjunto de dados e a m√©dia
print("Conjunto de Dados:", conjunto_de_dados)
print("M√©dia:", media)

# Calcule a m√©dia dos n√∫meros no conjunto de dados
media = sum(conjunto_de_dados) / tamanho_do_conjunto

# Calcule a vari√¢ncia dos n√∫meros no conjunto de dados
variancia = sum((x - media) ** 2 for x in conjunto_de_dados) / (tamanho_do_conjunto - 1)

# Imprima a vari√¢ncia
print("Vari√¢ncia:", variancia)
```

# Covari√¢ncia

<p ALIGN=justify>A covari√¢ncia √© uma medida estat√≠stica essencial que quantifica a rela√ß√£o linear entre duas vari√°veis aleat√≥rias. Em probabilidade e estat√≠stica, seu papel √© fundamental para compreender a interdepend√™ncia entre vari√°veis e fornecer insights valiosos sobre o comportamento conjunto de distribui√ß√µes de probabilidade.</p>

<p ALIGN=justify>Tamb√©m de import√¢ncia na an√°lise de sistemas de comunica√ß√£o s√£o as medidas estat√≠sticas entre duas vari√°veis aleat√≥rias. A covari√¢ncia de duas vari√°veis aleat√≥rias, X e Y, √© dada pelo valor esperado do produto das duas vari√°veis aleat√≥rias. A covari√¢ncia entre duas vari√°veis aleat√≥rias, $X$ e $Y$, √© expressa como:</p>

$$\text{Cov}(X, Y) = E[(X - \mu_X) \cdot (Y - \mu_Y)] \tag{8.39}$$

<p ALIGN=justify>Podemos expandir esta equa√ß√£o para obter:</p>

$$\text{Cov}(XY) =E[XY] - \mu_{x}\mu{y} \tag{8.40}$$

<p ALIGN=justify>Onde $E$ denota o operador de esperan√ßa, e $\mu_X$ e $\mu_Y$ s√£o as m√©dias de $X$ e $Y$, respectivamente.
Se as duas vari√°veis aleat√≥rias forem cont√≠nuas com densidade comum fX, Y(x, y), ent√£o o termo de esperan√ßa da Eq. √© dado por:</p>

$$E[XY] =  \int_{-\infty}^{\infty}  \int_{-\infty}^{\infty} xy \cdot f_{X,Y}(x,y) \,dxdy \tag{8.41}$$

<p ALIGN=justify>Se as duas vari√°veis aleat√≥rias forem independentes, ent√£o:</p>

$$E[XY] =  \int_{-\infty}^{\infty}  \int_{-\infty}^{\infty} xy \cdot f_{X,Y}(x,y) \,dxdy$$

$$ =  \int_{-\infty}^{\infty} x \cdot f_{X}(x) \,dx \int_{-\infty}^{\infty} y \cdot f_{Y}(y) \,dy$$

$$ = E[X]E[Y] \tag{8.42}$$

<p ALIGN=justify>Como poderia ser intuitivamente esperado. Substituindo este resultado na Equa√ß√£o 8.40, vemos que a covari√¢ncia de vari√°veis aleat√≥rias independentes √© zero. Deve ser observado, entretanto, que o oposto nem sempre √© verdadeiro: covari√¢ncia zero n√£o implica, em geral, em independ√™ncia.</p>


# Interpreta√ß√£o Probabil√≠stica

A. **Covari√¢ncia Positiva:** Indica que, em m√©dia, quando uma vari√°vel √© maior que sua m√©dia, a outra vari√°vel tamb√©m tende a ser maior que sua m√©dia. Sinaliza uma rela√ß√£o positiva.

B. **Covari√¢ncia Negativa:** Indica que, em m√©dia, quando uma vari√°vel √© maior que sua m√©dia, a outra vari√°vel tende a ser menor que sua m√©dia. Indica uma rela√ß√£o negativa.

C. **Covari√¢ncia Zero:** Sugere aus√™ncia de uma rela√ß√£o linear √≥bvia entre as vari√°veis. No entanto, n√£o implica independ√™ncia total.



# Covari√¢ncia Amostral

<p ALIGN=justify>Em situa√ß√µes pr√°ticas, lidamos frequentemente com amostras em vez de popula√ß√µes inteiras. A covari√¢ncia amostral √© calculada por:</p>

$$\text{Cov}_{\text{amostral}}(X, Y) = \frac{1}{n-1} \sum_{i=1}^{n} (x_i - \bar{X}) \cdot (y_i - \bar{Y}) $$

<p ALIGN=justify>onde $n$ √© o tamanho da amostra, $x_i$ e $y_i$ s√£o as observa√ß√µes individuais, e $\bar{X}$ e $\bar{Y}$ s√£o as m√©dias amostrais.</p>

<p ALIGN=justify>A covari√¢ncia desempenha um papel crucial na compreens√£o das rela√ß√µes entre vari√°veis aleat√≥rias em probabilidade e estat√≠stica, proporcionando uma base s√≥lida para an√°lises mais avan√ßadas e tomada de decis√µes informadas.</p>

<p ALIGN=justify>Vamos considerar um exemplo em que queremos calcular a covari√¢ncia entre as alturas (em cent√≠metros) e os pesos (em quilogramas) de um grupo de pessoas. A covari√¢ncia √© uma medida que indica como duas vari√°veis se comportam juntas em termos de desvio em rela√ß√£o √†s m√©dias.</p>

# Contextualiza√ß√£o do Problema

<p ALIGN=justify>Suponha que tenhamos as seguintes listas de alturas e pesos de um grupo de pessoas:</p>

```{python}
alturas = [160, 165, 170, 175, 180]  # Alturas em cent√≠metros
pesos = [50, 60, 65, 70, 75]  # Pesos em quilogramas
```

<p ALIGN=justify>Queremos calcular a covari√¢ncia entre essas duas vari√°veis para entender como elas variam juntas.</p>

# C√°lculo da Covari√¢ncia

<p ALIGN=justify>A f√≥rmula para calcular a covari√¢ncia amostral entre duas vari√°veis X e Y √© dada por:</p>

$$ \text{cov}(X, Y) = \frac{\sum_{i=1}^{n}(x_i - \bar{X})(y_i - \bar{Y})}{n-1} $$

<p ALIGN=justify>Onde:</p>

- $x_i$ e $y_i$ s√£o as observa√ß√µes individuais de $X$ e $Y$, respectivamente.

- $\bar{X}$ e $\bar{Y}$ s√£o as m√©dias de $X$ e $Y$, respectivamente.

- $n$ √© o n√∫mero de observa√ß√µes.

# Passo a Passo do C√°lculo

1. Calcular as m√©dias de altura $(\bar{X})$ e peso $(\bar{Y})$.

2. Calcular as diferen√ßas entre cada altura e a m√©dia de altura $(x_i - \bar{X})$ e cada peso e a m√©dia de peso $(y_i - \bar{Y})$.

3. Multiplicar as diferen√ßas correspondentes $(x_i - \bar{X}) \times (y_i - \bar{Y})$.

4. Somar todos os produtos calculados.

5. Dividir a soma pelo n√∫mero de observa√ß√µes menos 1 $(n-1)$ para obter a covari√¢ncia amostral.


```{python}
import numpy as np

# Dados
alturas = np.array([160, 165, 170, 175, 180])
pesos = np.array([50, 60, 65, 70, 75])

# Passo 1: Calcular as m√©dias
media_alturas = np.mean(alturas)
media_pesos = np.mean(pesos)

# Passo 2: Calcular as diferen√ßas
diff_alturas = alturas - media_alturas
diff_pesos = pesos - media_pesos

# Passo 3: Multiplicar as diferen√ßas correspondentes
produtos = diff_alturas * diff_pesos

# Passo 4: Somar todos os produtos
soma_produtos = np.sum(produtos)

# Passo 5: Calcular a covari√¢ncia amostral
covariancia = soma_produtos / (len(alturas) - 1)

print(f'A covari√¢ncia entre alturas e pesos √©: {covariancia}')

```

# [Volta a P√°gina Inicial üè†](P√°gina-Inicial.html)