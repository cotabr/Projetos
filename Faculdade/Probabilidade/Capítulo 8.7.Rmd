---
title: "Cap√≠tulo 8.7 - Correla√ß√£o de Processos Aleat√≥rios"
author: 
- Denilson Silva (Discente)
- Dr. Rafael Suzuki Bayma (Docente)
date: "`r format(Sys.time(), '%d/%m/%y')`"
output: 
  rmdformats::readthedown
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(reticulate)
```

<p ALIGN=justify>Enquanto processos aleat√≥rios s√£o, por defini√ß√£o, imprevis√≠veis, geralmente observamos que as amostras do processo em tempos diferentes podem ser correlacionadas. Por exemplo, se $X(t_1)$ for grande, ent√£o tamb√©m podemos esperar que $X(t_1 + \tau)$ seja grande, se $\tau$ for pequeno. Para quantificar esta rela√ß√£o, considere a covari√¢ncia de duas vari√°veis aleat√≥rias, definida na Se√ß√£o 8.2, aplicada a amostras do processo aleat√≥rio $X(t)$ nos tempos $t_1$ e $t_2$. Ou seja, a covari√¢ncia de duas vari√°veis aleat√≥rias $X(t1)$ e $X(t_2)$ √© dada por:</p>

$$
\textrm{Cov}(X(t_1), X(t_2))=E[X(t_1), X(t_2)]-\mu_{X(t_1)}\mu_{X(t_2)}\tag{8.64}
$$

<p ALIGN=justify>Definimos o primeiro termo do lado direito da Eq. (8.64) como a autocorrela√ß√£o do processo aleat√≥rio e utilizamos a nota√ß√£o gen√©rica:</p>

$$
R_{X(t,s)}=E[X(t)X^*(s)]\tag{8.65}
$$

<p ALIGN=justify>Na qual utilizamos o asterisco para representar o conjugado complexo para quando $X(t)$ for de valor complexo. Se $X(t)$ √© estacion√°rio de segunda ordem ou mais, ent√£o a Equa√ß√£o 8.64 pode ser escrita por:</p>

\begin{align*}
R_{X(t,s)}&=E[X(t)X^*(s)]\\
&=R_X(t-s)\tag{8.66}
\end{align*}

<p ALIGN=justify>A estacionariedade de segunda ordem tamb√©m implica que a m√©dia do processo aleat√≥rio √© constante. Se a m√©dia √© zero, ent√£o as fun√ß√µes de autocorrela√ß√£o e covari√¢ncia do processo aleat√≥rio s√£o equivalentes. A seguir ser√° mostrada a import√¢ncia da fun√ß√£o de autocorrela√ß√£o como descritor de processos aleat√≥rios. Para v√°rias aplica√ß√µes, n√£o precisamos que um processo aleat√≥rio tenha todas as propriedades necess√°rias para ser estacion√°rio de segunda ordem. Em particular geralmente precisamos apenas que:</p>

1. A m√©dia do processo aleat√≥rio √© uma constante independente do tempo: $E[X(t)] = \mu_X$ para todo t.

2. A autocorrela√ß√£o de um processo aleat√≥rio depende apenas da diferen√ßa de tempo: $E[X(t) X^*(t ‚Äì \tau)] = R_X(\tau)$, para todo t e $\tau$.
 
<p ALIGN=justify>Se um processo aleat√≥rio possui estas duas propriedades, ent√£o podemos dizer que ele √© estacion√°rio de sentido amplo ou fracamente estacion√°rio. Note que a estacionariedade de sentido amplo n√£o implica em estacionariedade de segunda ordem. Nem estacionariedade de segunda ordem implica em estacionariedade de sentido amplo, pois os momentos de primeira e segunda ordem podem n√£o existir. No restante do livro, iremos assumir que todos os processos de interesse s√£o estacion√°rios em sentido amplo.</p>

# Propriedades da fun√ß√£o de autocorrela√ß√£o
<p ALIGN=justify>A fun√ß√£o de autocorrela√ß√£o de um processo aleat√≥rio estacion√°rio em sentido amplo possui as seguintes propriedades para um processo de valor real:</p>

>**PROPRIEDADE 1 ‚Äì POT√äNCIA DE UM PROCESSO ESTACION√ÅRIO EM SENTIDO AMPLO** O segundo momento ou valor m√©dio quadr√°tico de um processo aleat√≥rio de valor real √© dado por:

\begin{align*}
R_X(0)&=E[X(t)X(t)]\\
&=E[X^2(t)]\tag{8.67}
\end{align*}

<p ALIGN=justify>O valor m√©dio quadr√°tico √©, portanto, equivalente √† pot√™ncia m√©dia do processo.</p>

>**PROPRIEDADE 2 ‚Äì SIMETRIA** A correla√ß√£o de um processo aleat√≥rio estacion√°rio em sentido amplo de valor real possui simetria par. Para mostrar isto, considere:

\begin{align*}
R_X(-\tau)&=E[X(t)X(t+\tau)]\\
&=E[X(t+\tau)X(t)]\\
&=R_X(\tau)\tag{8.68    }
\end{align*}

>**PROPRIEDADE 3 ‚Äì VALOR M√ÅXIMO** A fun√ß√£o de autocorrela√ß√£o de um processo aleat√≥rio estacion√°rio em sentido amplo √© m√°xima na origem. Para mostrar esta propriedade para um processo de valor real, forme quantidade n√£o negativa:

\begin{align*}
0&\leq E[(X(t)\pm X(t-\tau))^2]\\
&\leq E[X^2(t)]+E[X^2(t-\tau)]\pm 2E[X(t)X(t-\tau)]\\
&\leq 2R_X(0)\pm 2R_X(\tau)\tag{8.69}
\end{align*}

<p ALIGN=justify>Reorganizando a √∫ltima rela√ß√£o, temos $R_X(0) \geq |R_X(\tau)|$.</p>

<p ALIGN=justify>O significado f√≠sico da fun√ß√£o de autocorrela√ß√£o $R_X (\tau)$ √© que ela fornece uma maneira de descrever a interdepend√™ncia de duas vari√°veis aleat√≥rias obtidas pela observa√ß√£o do processo aleat√≥rio $X(t)$ $\tau$ segundos separados uma da outra. √â, portanto, aparente que qu√£o mais rapidamente o processo aleat√≥rio $X(t)$ varia como o tempo, mais rapidamente a fun√ß√£o de autocorrela√ß√£o $R_X(\tau)$ ir√° diminuir de seu m√°ximo $R_X(0)$ quando $\tau$ aumenta. Este decaimento pode ser caracterizado pelo tempo de decorrela√ß√£o $\tau_0$, especificamente, para $\tau > \tau_0$, a amplitude da correla√ß√£o $R_X(\tau)$ permanece abaixo de um valor preestabelecido. Podemos, portanto, definir o tempo de decorrela√ß√£o $\tau_0$ de um 
processo estacion√°rio $X(t)$ de m√©dia zero como o tempo para que a amplitude da fun√ß√£o de autocorrela√ß√£o $R_X(\tau)$ diminua, digamos, para 1% de seu valor m√°ximo em $R_X(0)$.</p>

# Ergodicidade

<p ALIGN=justify>Para determinar as propriedades estat√≠sticas de um processo aleat√≥rio, geralmente precisamos calcular esperan√ßas. A esperan√ßa de um processo aleat√≥rio em um ponto particular no tempo requer realiza√ß√µes independentes separadas do processo aleat√≥rio. Por exemplo, para um processo aleat√≥rio $X(t)$ com $N$ realiza√ß√µes equiprov√°veis $\{x_j (t): j = 1, 2, .., N\}$, o valor esperado e o segundo momento do processo aleat√≥rio no tempo $t = t_k$ s√£o, respectivamente, dados pelas m√©dias da fam√≠lia:</p>

$$
E[X(t_k)]=\frac{1}{N}\sum^N_{j=1}x_j(t_k)\tag{8.70}
$$
e

$$
E[X^2(t_k)]=\frac{1}{N}\sum^N_{j=1}x_j^2(t_k)\tag{8.71}
$$

<p ALIGN=justify>Se o processo √© estacion√°rio em sentido amplo, ent√£o o valor m√©dio e o segundo momento calculados por estas duas equa√ß√µes n√£o dependem do tempo $t_k$.</p>

<p ALIGN=justify>Em problemas pr√°ticos envolvendo processos aleat√≥rios, o que geralmente estar√° dispon√≠vel para o usu√°rio n√£o √© o processo aleat√≥rio, mas uma de suas fun√ß√µes de amostra $x(t)$. Em tais casos, os par√¢metros mais facilmente medidos s√£o as m√©dias temporais. Por 
exemplo, a m√©dia temporal de uma fun√ß√£o amostra cont√≠nua obtida de um processo de valor real √© dada por:</p>

$$
\varepsilon [x]=\lim_{T\rightarrow \infty} \frac{1}{2T}\int^T_{-T}x(t)dt\tag{8.72}
$$

<p ALIGN=justify>E a autocorrela√ß√£o no tempo da fun√ß√£o amostra √© dada por:</p>

$$
R_x(\tau)=\lim_{T\rightarrow \infty} \frac{1}{2T}\int^T_{-T}x(t)x(t-\tau)dt\tag{8.73}
$$
 
<p ALIGN=justify>Ent√£o a quest√£o √©: Quando as m√©dias temporais de uma fun√ß√£o amostra s√£o iguais √†s m√©dias do espa√ßo amostral do processo aleat√≥rio correspondente? Intuitivamente, se as estat√≠sticas do processo aleat√≥rio X(t) n√£o mudarem com o tempo, ent√£o podemos esperar que as m√©dias temporais e as m√©dias do espa√ßo amostral sejam equivalentes.</p>

<p ALIGN=justify>Dependendo das propriedades estacion√°rias do processo aleat√≥rio, v√°rias m√©dias temporais das fun√ß√µes de amostra podem ser utilizadas para aproximar as m√©dias ou esperan√ßas do espa√ßo amostral correspondente. Processos aleat√≥rios para os quais esta equival√™ncia √© v√°lida s√£o ditos serem erg√≥dicos. Na maioria das aplica√ß√µes f√≠sicas, os processos estacion√°rios em sentido amplo s√£o erg√≥dicos, e, neste caso, as m√©dias temporais e esperan√ßas podem ser utilizadas uma no lugar da outra.</p>

<p ALIGN=justify>O leitor alerta ir√° notar que, tal como a estacionariedade, existem v√°rios graus de ergodicidade. As equival√™ncias das Equa√ß√µes (8.70) e (8.72) por um lado e as Equa√ß√µes (8.66) e (8.73) correspondentes por outro lado s√£o an√°logas √† forma de ergodicidade de primeira e 
segunda ordem. Al√©m disso, se assumirmos que o processo aleat√≥rio de valor real √© erg√≥dico, ent√£o podemos expressar a fun√ß√£o de autocorrela√ß√£o por:</p>

\begin{align*}
R_X(\tau)&=E[X(t)X(t-\tau)]\\
&=\lim_{T\rightarrow \infty} \frac{1}{2T}\int^T_{-T}x(t)x(t-\tau)dt\tag{8.74}
\end{align*}

<p ALIGN=justify>Na qual x(t) √© uma fun√ß√£o amostra do processo aleat√≥rio $X(t)$. Esta defini√ß√£o de autocorrela√ß√£o √© id√™ntica √† defini√ß√£o de correla√ß√£o para sinais de pot√™ncia determin√≠sticos como descrito no Cap√≠tulo 2. Como conseq√º√™ncia, a autocorrela√ß√£o de um processo aleat√≥rio erg√≥dico possui as mesmas propriedades da autocorrela√ß√£o de sinais determin√≠sticos.</p>
 
$$
\hat{R}_X(\tau_0)=\frac{1}{n}\sum^N_{n=1}x(t_n)x(t_n-\tau_0)\tag{8.75}
$$
 
<p ALIGN=justify>O conceito de ergodicidade tamb√©m leva naturalmente √† id√©ia de estimadores para a fun√ß√£o de autocorrela√ß√£o. Em particular, se $x(t)$ √© uma fun√ß√£o amostra de um processo erg√≥dico estacion√°rio em sentido amplo $X(t)$, ent√£o uma estimativa da autocorrela√ß√£o de um processo de valor real para o atraso $\tau=\tau_0$ √© na qual $\{t_n\}$ √© um conjunto conveniente de tempos de amostragem, uniformemente espa√ßados ou n√£o. Similar aos estimadores de m√©dia e vari√¢ncia de uma vari√°vel aleat√≥ria, esta estimativa de autocorrela√ß√£o √© motivada pela defini√ß√£o de frequ√™ncia relativa da probabilidade.</p>

# [Volta a P√°gina Inicial üè†](P√°gina-Inicial.html)
